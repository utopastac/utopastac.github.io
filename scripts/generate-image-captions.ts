/**
 * Generates content-based captions for job images using OpenAI Vision API.
 * Run from project root: npx tsx scripts/generate-image-captions.ts
 * Requires OPENAI_API_KEY in the environment.
 *
 * Writes src/data/job-image-captions.generated.ts. Re-run to add captions
 * for new images; existing entries are preserved.
 */

import * as fs from 'fs'
import * as path from 'path'
import { fileURLToPath } from 'url'

const __dirname = path.dirname(fileURLToPath(import.meta.url))
const root = path.resolve(__dirname, '..')

const GENERATED_PATH = path.join(root, 'src/data/job-image-captions.generated.ts')

const PROMPT = `Describe this image in one short sentence (under 15 words) suitable as alt text and a portfolio caption. Focus on what is shown: e.g. UI screen, app interface, diagram, or design artifact. Be specific and neutral. Reply with only the caption, no quotes or prefix.`

function getMime(ext: string): string {
  const m: Record<string, string> = {
    '.jpg': 'image/jpeg',
    '.jpeg': 'image/jpeg',
    '.png': 'image/png',
    '.gif': 'image/gif',
    '.webp': 'image/webp',
  }
  return m[ext.toLowerCase()] ?? 'image/jpeg'
}

async function getCaptionFromVision(imagePath: string, apiKey: string): Promise<string> {
  const ext = path.extname(imagePath)
  const mime = getMime(ext)
  const buffer = fs.readFileSync(imagePath)
  const base64 = buffer.toString('base64')
  const dataUrl = `data:${mime};base64,${base64}`

  const res = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini',
      max_tokens: 100,
      messages: [
        {
          role: 'user',
          content: [
            { type: 'text', text: PROMPT },
            {
              type: 'image_url',
              image_url: { url: dataUrl },
            },
          ],
        },
      ],
    }),
  })

  if (!res.ok) {
    const err = await res.text()
    throw new Error(`OpenAI API error ${res.status}: ${err}`)
  }

  const data = (await res.json()) as { choices?: { message?: { content?: string } }[] }
  const content = data.choices?.[0]?.message?.content?.trim()
  if (!content) throw new Error('Empty response from OpenAI')
  return content
}

function loadExistingCaptions(): Record<string, string> {
  if (!fs.existsSync(GENERATED_PATH)) return {}
  const content = fs.readFileSync(GENERATED_PATH, 'utf-8')
  const match = content.match(/export const JOB_IMAGE_CAPTIONS: Record<string, string> = (\{[\s\S]*?\});/)
  if (!match) return {}
  try {
    const json = match[1].replace(/'/g, '"').replace(/,\s*}/g, '}')
    return JSON.parse(json) as Record<string, string>
  } catch {
    return {}
  }
}

function writeGeneratedCaptions(captions: Record<string, string>): void {
  const entries = Object.entries(captions)
    .sort(([a], [b]) => a.localeCompare(b))
    .map(([src, caption]) => `  ${JSON.stringify(src)}: ${JSON.stringify(caption)},`)
    .join('\n')
  const content = `/**
 * Auto-generated by scripts/generate-image-captions.ts â€” do not edit.
 * Content-based captions for job images (vision API). Re-run the script to refresh.
 */

export const JOB_IMAGE_CAPTIONS: Record<string, string> = {
${entries}
}
`
  fs.writeFileSync(GENERATED_PATH, content, 'utf-8')
}

async function main(): Promise<void> {
  const apiKey = process.env.OPENAI_API_KEY
  if (!apiKey) {
    console.error('Set OPENAI_API_KEY in the environment.')
    process.exit(1)
  }

  // Dynamic import so we can resolve from project root when run via tsx
  const { JOBS } = (await import('../src/data/jobs.ts')) as { JOBS: { images?: { src: string }[] }[] }
  const allImages: string[] = []
  for (const job of JOBS) {
    for (const img of job.images ?? []) {
      allImages.push(img.src)
    }
  }

  const publicDir = path.join(root, 'public')
  const existing = loadExistingCaptions()
  const captions = { ...existing }
  let updated = 0

  for (const src of allImages) {
    if (captions[src]) {
      console.log('Skip (have caption):', src)
      continue
    }
    const decodedPath = decodeURIComponent(src).replace(/^\//, '')
    const imagePath = path.join(publicDir, decodedPath)
    if (!fs.existsSync(imagePath)) {
      console.warn('Image not found:', imagePath)
      continue
    }
    try {
      const caption = await getCaptionFromVision(imagePath, apiKey)
      captions[src] = caption
      updated++
      console.log(src, '->', caption)
      await new Promise((r) => setTimeout(r, 300))
    } catch (e) {
      console.error('Failed', src, e)
    }
  }

  writeGeneratedCaptions(captions)
  console.log('\nWrote', GENERATED_PATH, `(${updated} new, ${Object.keys(captions).length} total)`)
}

main()
